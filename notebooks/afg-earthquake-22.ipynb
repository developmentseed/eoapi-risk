{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eoAPI in Action - Afghanistan Earthquakes 2022\n",
    "\n",
    "The Jupyter Notebook is dedicated to analyzing the aftermath of the Afghanistan earthquakes in 2022.  The notebook should serve as an example for diving deeper into the available imagery pre and post event and assessing what it could be used for. \n",
    "\n",
    "Firstly, we'll delve into querying MAXAR's catalog of images of the event, and pinpointing those relevant to the regions affected by the earthquakes. \n",
    "\n",
    "If possible based on the images obtained, we'll shift our focus to finding signs of impact, employing sophisticated image analysis techniques to identify and interpret the changes in the landscape. Then we will try to determine the population affected by these seismic events, integrating demographic data with our impact analysis to estimate the extent of the humanitarian challenge. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we dive into the analysis, let's set up our environment by importing the necessary libraries. This step is crucial for ensuring that we have all the tools required for our data processing, analysis, and visualization tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "!python -m pip install httpx ipyleaflet matplotlib\n",
    "IPython.display.clear_output(wait=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import httpx\n",
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some key environment variables upfront is essential to interact with the eoAPI and streamline our analysis effectively. These variables will be the foundational parameters for our API queries and data handling. The crucial variables we'll set include:\n",
    "\n",
    "- stac_endpoint: This is the URL of the STAC (SpatioTemporal Asset Catalog) endpoint of eoAPI. It serves as the entry point for querying and retrieving metadata about the satellite imagery available in our catalog.\n",
    "\n",
    "- collection_id: Each collection of images in the eoAPI is identified by a unique ID. By specifying our collection_id, we can access the specific dataset relevant to the Afghanistan earthquake regions.\n",
    "\n",
    "- raster_endpoint: This variable defines the endpoint for accessing raster data within the eoAPI. It allows us to retrieve and manipulate satellite imagery, which is crucial for our impact analysis and visualization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_endpoint = \"https://eoapi.ifrc-risk.k8s.labs.ds.io/stac\"\n",
    "collection_id = \"MAXAR_afghanistan_earthquake22\"\n",
    "raster_endpoint = \"https://eoapi.ifrc-risk.k8s.labs.ds.io/raster\"\n",
    "event_date_str =  \"Wednesday, June 22, 2022\"\n",
    "event_datetime = datetime.strptime(event_date_str, \"%A, %B %d, %Y\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying eoAPI to Find Images\n",
    "\n",
    "In this section, we will take the first critical step of our analysis, which is querying our image catalog using the eoAPI. This process involves accessing the vast repository of satellite data specific to the regions affected by the Afghanistan earthquakes. Our goal is to use the stac_endpoint and collection_id to filter and retrieve the images that are most relevant to our study. We want to streamline the querying process to efficiently select images that provide valuable insights into the seismic impacts. This step is not just about fetching data; it's about strategically selecting the right datasets to form the foundation of our subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afghanistan Earthquake: Maxar OpenData | On Wednesday, June 22, 2022, a 5.9 magnitude earthquake struck eastern Afghanistan. It has been estimated that more than 1,000 have been killed and many more wounded. Houses have been reduced to rubble and an unknown number of people remain stuck under debris. In outlaying areas rescue operations were complicated by difficult conditions including heavy rain, landslides and villages being located in inaccessible hillsides areas. Wednesday's earthquake was the deadliest in Afghanistan since 2022. It struck about 27 miles (44 km) from the southeastern city of Khost, near the border with Pakistan.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "collection_info = httpx.get(f\"{stac_endpoint}/collections/{collection_id}\").json()\n",
    "print(f\"{collection_info['title'] if 'title' in collection_info else 'NA'}: {collection_info['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42698777938548ff9968c24613604990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[29.60082468671302, 79.33739695318904], controls=(ZoomControl(options=['position', 'zoom_in_text', …"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": [\n",
    "        {\n",
    "            'type': 'Feature',\n",
    "            'geometry': {\n",
    "                'type': 'Polygon',\n",
    "                'coordinates': [[\n",
    "                    [bbox[0], bbox[1]],\n",
    "                    [bbox[2], bbox[1]],\n",
    "                    [bbox[2], bbox[3]],\n",
    "                    [bbox[0], bbox[3]],\n",
    "                    [bbox[0], bbox[1]],\n",
    "                ]]\n",
    "            },\n",
    "            'properties': {}\n",
    "        }\n",
    "        for bbox in collection_info[\"extent\"][\"spatial\"][\"bbox\"] if \"extent\" in collection_info\n",
    "    ]\n",
    "}\n",
    "\n",
    "mainbbox = collection_info[\"extent\"][\"spatial\"][\"bbox\"][0]\n",
    "\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((mainbbox[1] + mainbbox[3]) / 2,(mainbbox[0] + mainbbox[2]) / 2),\n",
    "    zoom=5\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(data=geojson)\n",
    "m.add_layer(geo_json)\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main bbox is too large given the majority of our data is in the north-east corner. We can manually set the bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bounds = [69.54357828617795, 33.08936792525831, 69.56357828617795, 33.10936792525831]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_url = f\"{stac_endpoint}/collections/{collection_id}/items\"\n",
    "items = httpx.get(items_url).json() \n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Number of Items: 395\n"
     ]
    }
   ],
   "source": [
    "afg_items = []\n",
    "\n",
    "url = items_url\n",
    "while True:\n",
    "    items = httpx.get(url, params={\"limit\": 200}).json()\n",
    "    \n",
    "    afg_items.extend(items[\"features\"])\n",
    "    next_link = list(filter(lambda link: link[\"rel\"] == \"next\", items[\"links\"]))\n",
    "    if next_link:\n",
    "        url = next_link[0][\"href\"]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"Actual Number of Items: {len(afg_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items before event: 223\n",
      "Number of items after event: 172\n"
     ]
    }
   ],
   "source": [
    "afg_items_pre = []\n",
    "afg_items_post = []\n",
    "\n",
    "for item in afg_items:\n",
    "    item_datetime = datetime.strptime(item['properties']['datetime'].replace('Z', ''), \"%Y-%m-%dT%H:%M:%S\") \n",
    "    if item_datetime < event_datetime:\n",
    "        afg_items_pre.append(item_datetime)\n",
    "    else:\n",
    "        afg_items_post.append(item_datetime)\n",
    "\n",
    "print(f\"Number of items before event: {len(afg_items_pre)}\")\n",
    "print(f\"Number of items after event: {len(afg_items_post)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9e562cc6894036b740bc0018f5c978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[33.099367925258306, 69.55357828617795], controls=(ZoomControl(options=['position', 'zoom_in_text',…"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((main_bounds[1] + main_bounds[3]) / 2,(main_bounds[0] + main_bounds[2]) / 2),\n",
    "    zoom=7\n",
    ")\n",
    "\n",
    "event_date = datetime(2022, 6, 22, hour=0, minute=0)\n",
    "\n",
    "# Use a styling function to show where we have before/after items\n",
    "def style_function(feature):\n",
    "    d = datetime.strptime(feature[\"properties\"][\"datetime\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    return {\n",
    "        \"fillOpacity\": 0.1,\n",
    "        \"weight\": 0.1,\n",
    "        # Blue for pre-event / red for post-event\n",
    "        \"fillColor\": \"#0000ff\" if d < event_date else \"#ff0000\"\n",
    "    }\n",
    "\n",
    "geojson = ipyleaflet.leaflet.GeoJSON(data={\"type\": \"FeatureCollection\", \"features\": afg_items}, style_callback=style_function)\n",
    "m.add_layer(geojson)\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon closer examination of our dataset, we have encountered several significant issues that must be addressed. Firstly, the temporal extents of the data we've queried are not well-formatted, which poses a challenge in accurately assessing the satellite capture timeline. This formatting issue could lead to difficulties in understanding the precise timeframes of the images, particularly in relation to the earthquake events. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the images\n",
    "\n",
    "Even without specific post-event images, we will create a mosaic to simultaneously visualize all the pre-events. The mosaic could be overlaid with any custom data available from other sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tilejson': '2.2.0',\n",
       " 'version': '1.0.0',\n",
       " 'scheme': 'xyz',\n",
       " 'tiles': ['http://eoapi.ifrc-risk.k8s.labs.ds.io/raster/collections/MAXAR_afghanistan_earthquake22/items/42_120200200330_10300100C084CC00/tiles/WebMercatorQuad/{z}/{x}/{y}@1x?assets=visual'],\n",
       " 'minzoom': 12,\n",
       " 'maxzoom': 19,\n",
       " 'bounds': [69.31926076847,\n",
       "  32.941313704603466,\n",
       "  69.37629464192838,\n",
       "  32.98939210855889],\n",
       " 'center': [69.34777770519919, 32.965352906581174, 12]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = items[\"features\"][0]\n",
    "tilejson = httpx.get(\n",
    "    f\"{raster_endpoint}/collections/{collection_id}/items/{item['id']}/tilejson.json\",\n",
    "    params = (\n",
    "        (\"assets\", \"visual\"),  # THIS PARAMETER IS MANDATORY\n",
    "        (\"minzoom\", 12),  # By default the tiler will use 0\n",
    "        (\"maxzoom\", 19), # By default the tiler will use 24\n",
    "    )\n",
    ").json()\n",
    "tilejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b679ed68432e4cd6a72e6b8ed32611d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[32.965352906581174, 69.34777770519919], controls=(ZoomControl(options=['position', 'zoom_in_text',…"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = tilejson[\"bounds\"]\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((bounds[1] + bounds[3]) / 2,(bounds[0] + bounds[2]) / 2),\n",
    "    zoom=12\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(\n",
    "    data=item,\n",
    "    style={\n",
    "        'opacity': 1, 'dashArray': '9', 'fillOpacity': 0., 'weight': 4\n",
    "    }\n",
    ")\n",
    "m.add_layer(geo_json)\n",
    "\n",
    "tiles = ipyleaflet.leaflet.TileLayer(\n",
    "    url=tilejson[\"tiles\"][0],\n",
    "    min_zoom=tilejson[\"minzoom\"],\n",
    "    max_zoom=tilejson[\"maxzoom\"],\n",
    "    bounds=[\n",
    "        [bounds[1], bounds[0]],\n",
    "        [bounds[3], bounds[2]],\n",
    "\n",
    "    ],\n",
    ")\n",
    "\n",
    "m.add_layer(tiles)\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
