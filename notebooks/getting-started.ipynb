{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with STAC and eoAPI\n",
    "\n",
    "## A Foundational Guide for the IFRC's Geospatial Data Analysis\n",
    "\n",
    "### Overview\n",
    "\n",
    "Welcome to this guide designed to introduce you to the world of SpatioTemporal Asset Catalog (STAC), Cloud Optimized Geotiffs (COGs), and eoAPI. Tailored for the International Federation of Red Cross and Red Crescent Societies (IFRC), this Jupyter Notebook aims to provide you with the foundational knowledge and practical skills necessary to effectively utilize these powerful tools in geospatial data management and analysis.\n",
    "\n",
    "### Context\n",
    "\n",
    "The notebook delves into the essentials of using eoAPI, offering insights into STAC and COGs. We will explore how eoAPI facilitates querying metadata and visualizing the underlying referenced data. All notebooks of the repository run within a specially configured cluster, integrating a deployed instance of eoAPI and JupyterHub to provide a seamless, hands-on experience.\n",
    "\n",
    "### STAC, COG, and eoAPI\n",
    "\n",
    "- **STAC**: We begin with an introduction to STAC, explaining its structure and critical role in damage assessment and risk management.\n",
    "- **COG**: Next, we explore COGs and why they are pivotal in modern geospatial data handling.\n",
    "- **eoAPI**: Finally, we discuss eoAPI, detailing its functionalities and importance in this ecosystem.\n",
    "\n",
    "In this notebook, we leverage Maxar's high-resolution satellite imagery, acquired explicitly for the M7.8 and M7.5 Kahramanmaras earthquakes in Turkey on February 6, 2023. This data, pivotal for emergency response and risk assessment, has been ingested into our instance of eoAPI deployed on the cluster. The imagery, available as Cloud Optimized Geotiffs (COGs) with accompanying STAC metadata, enables streamlined analysis and visualization of the earthquake's impact. Maxar's data, being analysis-ready and cloud-optimized, provides a rich resource for demonstrating the capabilities of eoAPI in handling large-scale geospatial datasets in a crisis context.\n",
    "\n",
    "This notebook is the foundational guide for the IFRC's of eoAPI and associated resources. It is structured to guide you through these concepts, culminating in a hands-on demonstration of using eoAPI to query and visualize earth observation data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAC: What is it? Why is it important? How can I learn more?\n",
    "\n",
    "### What is STAC (SpatioTemporal Asset Catalog)?\n",
    "\n",
    "The SpatioTemporal Asset Catalog (STAC) is a specification designed to standardize how geospatial data is organized and accessed. It's a community-driven standard developed collaboratively by experts and stakeholders in the geospatial data field. STAC provides a common language and structure for describing geospatial information, making it easier to index, discover, and manage spatial data across various platforms and systems. One of the critical features of STAC is its format: simple JSON objects, which are both human-readable and machine-processable, ensuring ease of use and broad accessibility.\n",
    "\n",
    "A fundamental aspect of STAC's design is its hierarchical organization, comprising Catalogs, Collections, and Items. At the highest level, **Catalogs** serve as containers that organize and provide access to Collections and Items. **Collections** represent a group of Items that share common properties, metadata, and structure, typically representing a dataset or a series of datasets. Within Collections, **Items** are individual pieces of data, each containing specific geospatial information, such as location and time. Crucially, each Item includes links to its Assets, which are the files associated with the data, such as imagery, thumbnails, or other related resources. These **Assets** are integral to the utility of each Item, providing the data required for analysis and visualization. This structured approach ensures a consistent and intuitive way to access and manage vast amounts of geospatial data, making STAC an efficient tool for data providers and users.\n",
    "\n",
    "### Why is STAC Important?\n",
    "\n",
    "STAC is critical in the modern earth observation stack, particularly for large-scale environmental monitoring, disaster response, and risk assessment scenarios. Its standardized, community-backed approach facilitates:\n",
    "\n",
    "- **Efficient Data Discovery**: Simplifying the finding of relevant geospatial data across vast datasets.\n",
    "- **Interoperability**: Enabling different systems and tools to access and use geospatial data seamlessly.\n",
    "- **Scalability**: Supporting the management of increasingly large and complex datasets is a common challenge in geospatial analysis.\n",
    "- **Inclusivity and Collaboration**: STAC evolves through collective insights as a community-driven standard, ensuring it remains relevant and effective for various use cases.\n",
    "\n",
    "For organizations like the IFRC, STAC's capabilities are invaluable in rapidly accessing and analyzing data for humanitarian aid, disaster relief, and risk management purposes.\n",
    "\n",
    "### How Can I Learn More?\n",
    "\n",
    "To deepen your understanding of STAC and its applications:\n",
    "\n",
    "- **STAC Specification**: Dive into the official [STAC Specification](https://stacspec.org/) for detailed documentation and standards.\n",
    "- **STAC Index**: Explore the [STAC Index](https://stacindex.org/), a comprehensive resource listing STAC implementations, tools, and data catalogs, to get a better grasp of the ecosystem and its applications.\n",
    "- **Developer Best Practices**: For a more technical perspective, review the [STAC Best Practices](https://github.com/radiantearth/stac-spec/blob/master/best-practices.md) on GitHub, offering in-depth guidance for developers working with STAC.\n",
    "\n",
    "As we progress through this notebook, we'll explore applying STAC principles using eoAPI in practical scenarios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COG: What is it? Why is it important? How can I learn more?\n",
    "\n",
    "### What is a COG (Cloud Optimized Geotiff)?\n",
    "\n",
    "A Cloud Optimized GeoTIFF (COG) is a variant of the TIFF image format tailored explicitly for optimized access over a network. A raster format specifies a particular layout of internal data within the GeoTIFF specification, allowing for efficient, subsetted, or aggregated access. This format is designed to enable efficient workflows on the cloud by leveraging HTTP GET range requests for just the parts of the file needed. COGs are regular GeoTIFF files, making them backward compatible with other geospatial software but with an internal organization that enables more efficient data access and processing.\n",
    "\n",
    "### Why is COG Important?\n",
    "\n",
    "COGs represent a significant advancement in geospatial data handling, primarily due to:\n",
    "\n",
    "- **Efficient Imagery Data Access**: COG-aware software can stream just the portion of data it needs, significantly improving processing times and enabling real-time workflows that were previously not possible.\n",
    "- **Internal Compression and Optimized Read Performance**: COGs are internally compressed, meaning the inner blocks in a GeoTIFF are already compressed. This internal compression allows COG readers to decompress only the specific portion of the file requested rather than the entire file.\n",
    "- **Reduced Duplication of Data**: COGs enable diverse software to access a single file online, reducing the need to copy and cache data.\n",
    "- **Legacy Compatibility**: Traditional GIS software can treat cloud-optimized geoTIFFs just like normal geoTIFFs, simplifying data management.\n",
    "\n",
    "### How Can I Learn More?\n",
    "\n",
    "For a deeper dive into COGs and to understand their implementation and usage:\n",
    "\n",
    "- **Official Documentation**: Visit the [COG website](https://www.cogeo.org/) for a comprehensive understanding of COGs and their implementation details.\n",
    "- **Cloud Native Geospatial Formats Guide**: The [Cloud Native Geospatial Formats Guide](https://guide.cloudnativegeo.org/) offers detailed insights into COGs, including advanced details and working examples to help you grasp the practical applications of this format.\n",
    "\n",
    "In the following sections, we'll explore the practical application of COGs in conjunction with eoAPI, focusing on how they can be utilized for efficient geospatial data management and visualization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eoAPI: What is it? Why is it important? How can I learn more?\n",
    "\n",
    "### What is eoAPI?\n",
    "\n",
    "eoAPI is an open-source framework for accessing and utilizing Earth Observation (EO) data. It simplifies constructing a cloud-native EO infrastructure by providing sensible defaults for most EO and geospatial infrastructure needs. eoAPI is modular, allowing for easy customization to specific requirements. Its key features include:\n",
    "\n",
    "- **STAC Powered**: Utilizes a suite of STAC-focused technologies.\n",
    "- **Sensible Defaults**: Facilitates seamless deployment, configuration, and customization.\n",
    "- **Cloud Agnostic**: Capable of quick deployment and scaling of EO services anywhere.\n",
    "\n",
    "### Why is eoAPI Important?\n",
    "\n",
    "eoAPI addresses the challenge of making EO data easily discoverable, interoperable, ingestible, and optimized for integration into modern applications and decision-making tools. Simply put, it lowers the barrier of entry to earth observation data to a broader range of developers, scientists, and the general public. This is crucial for understanding our changing planet and maximizing the societal impact of EO data. eoAPI's framework supports end-to-end EO infrastructure, including data cataloging, searching, visualization, and access, making it a powerful tool for organizations like the IFRC in their mission-driven work.\n",
    "\n",
    "### How Can I Learn More?\n",
    "\n",
    "To explore eoAPI further:\n",
    "\n",
    "- **Official Documentation and Guides**: Visit [eoAPI's website](https://eoapi.dev/) for comprehensive documentation and guides on deploying and using the framework.\n",
    "- **GitHub Repository**: Check out the [eoAPI GitHub repository](https://github.com/developmentseed/eoapi) for source code, updates, and community contributions.\n",
    "\n",
    "We'll delve into effectively utilizing eoAPI with STAC and COGs as we proceed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eoAPI in Action - Kahramanmaras Earthquakes\n",
    "\n",
    "### Background\n",
    "\n",
    "This section will review the different [eoAPI](https://github.com/developmentseed/eoAPI) services using the latest Open data from Maxar acquired for the M7.8 and M7.5 Kahramanmaras earthquakes in Turkey on February 6, 2023. For more information on the event, visit [USGS' article](https://www.usgs.gov/news/featured-story/m78-and-m75-kahramanmaras-earthquake-sequence-near-nurdagi-turkey-turkiye)\n",
    "\n",
    "Maxar provides pre and post-event high-resolution satellite imagery in support of emergency planning, risk assessment, monitoring of staging areas and emergency response, damage assessment, and recovery. These images are generated using the Maxar ARD pipeline, tiled on an organized grid in analysis-ready cloud-optimized formats.\n",
    "\n",
    "Maxar releases open data for select sudden-onset major crisis events. In addition to making the formatted COG data freely available on AWS, they also add static STAC metadata alongside the images. Having the STAC items already created makes ingestion into the PgSTAC database easy because we don't have to produce the items ourselves and read the images.\n",
    "\n",
    "To learn more about ingesting the Maxar OpenData STAC catalog into PgSTAC, see https://github.com/vincentsarago/MAXAR_opendata_to_pgstac. For IFRC, data ingestion to the Kubernetes cluster can be trigger via [GitHub actions](https://github.com/developmentseed/eoapi-risk/tree/main/.github/workflows) directly on the repository.\n",
    "\n",
    "### Structure of eoAPI in Action\n",
    "\n",
    "0. Setting Up\n",
    "1. How to query STAC\n",
    "    - How to query Collections\n",
    "    - How to query Items\n",
    "2. Find Items within a data range\n",
    "3. Visualizing an Asset\n",
    "4. Visualizing multiple Assets with Mosaics\n",
    "5. Comparing pre and post events Mosaics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up\n",
    "\n",
    "Before we start querying the STAC endpoint, there are a few setup steps to ensure that our environment has all the necessary tools and libraries. This section will guide you through installing the required packages and importing essential modules.\n",
    "\n",
    "We must install two packages: **`httpx`** for making HTTP requests and **`ipyleaflet`** for interactive mapping in Jupyter notebooks.\n",
    "\n",
    "Run the following command in your Jupyter Notebook to install these packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: ipyleaflet in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (0.17.3)\n",
      "Requirement already satisfied: certifi in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from httpx) (2023.5.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from httpx) (0.17.3)\n",
      "Requirement already satisfied: idna in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from httpx) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from httpx) (1.3.0)\n",
      "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipyleaflet) (8.1.0)\n",
      "Requirement already satisfied: traittypes<3,>=0.2.1 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipyleaflet) (0.2.1)\n",
      "Requirement already satisfied: xyzservices>=2021.8.1 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipyleaflet) (2023.7.0)\n",
      "Requirement already satisfied: branca>=0.5.0 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipyleaflet) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from branca>=0.5.0->ipyleaflet) (3.1.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx) (3.7.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipywidgets<9,>=7.6.0->ipyleaflet) (3.0.8)\n",
      "Requirement already satisfied: exceptiongroup in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx) (1.1.1)\n",
      "Requirement already satisfied: backcall in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from jinja2->branca>=0.5.0->ipyleaflet) (2.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/zacdez/.pyenv/versions/3.10.5/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipyleaflet) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install httpx ipyleaflet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command uses pip, Python's package installer, to download and install the **`httpx`** and **`ipyleaflet`** packages from the Python Package Index (PyPI).\n",
    "\n",
    "### Importing Modules\n",
    "\n",
    "After installing the necessary packages, we need to import some standard and installed modules that will be used throughout our queries. The following Python code imports these modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import httpx\n",
    "\n",
    "import ipyleaflet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`datetime`**: This module from Python's standard library works with dates and times. It's especially useful when dealing with time-based geospatial data.\n",
    "- **`json`**: This module is used for JSON data handling. Since responses from STAC endpoints are typically in JSON format, this module is crucial for parsing and processing these responses.\n",
    "- **`httpx`**: A powerful and user-friendly HTTP client for Python. We will use it to send requests to the STAC endpoint.\n",
    "- **`ipyleaflet`**: A library for creating interactive maps in Jupyter notebooks. It's beneficial for visualizing geospatial data on a map.\n",
    "\n",
    "Ensure that all imports run successfully. Double-check that the required packages are installed correctly if there are any issues."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to query STAC\n",
    "\n",
    "The SpatioTemporal Asset Catalog (STAC) provides a standardized way to expose geospatial data and metadata. This section will explore how to query the STAC endpoint, specifically for the International Federation of Red Cross and Red Crescent Societies (IFRC).\n",
    "\n",
    "The eoAPI STAC endpoint for IFRC is available at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_endpoint = \"https://eoapi.ifrc-risk.k8s.labs.ds.io/stac\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This endpoint is your gateway to accessing various geospatial datasets and metadata associated with IFRC's initiatives.\n",
    "\n",
    "#### How to query Collections\n",
    "\n",
    "Collections in STAC represent higher-level groupings under which items (geospatial datasets) are associated. These collections are folders containing related items. To start querying, we'll focus on these collections to understand the types of data available.\n",
    "\n",
    "To query collections, we can use `httpx` to use a HTTP GET request to the **`/collections`** endpoint. To give you an overview of the STAC specification, here's what the first Collection of the requests looks like in its JSON format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'MAXAR_BayofBengal_Cyclone_Mocha_May_23',\n",
       " 'type': 'Collection',\n",
       " 'links': [{'rel': 'items',\n",
       "   'type': 'application/geo+json',\n",
       "   'href': 'https://stac.eoapi.dev/collections/MAXAR_BayofBengal_Cyclone_Mocha_May_23/items'},\n",
       "  {'rel': 'parent',\n",
       "   'type': 'application/json',\n",
       "   'href': 'https://stac.eoapi.dev/'},\n",
       "  {'rel': 'root',\n",
       "   'type': 'application/json',\n",
       "   'href': 'https://stac.eoapi.dev/'},\n",
       "  {'rel': 'self',\n",
       "   'type': 'application/json',\n",
       "   'href': 'https://stac.eoapi.dev/collections/MAXAR_BayofBengal_Cyclone_Mocha_May_23'}],\n",
       " 'extent': {'spatial': {'bbox': [[91.831615,\n",
       "     19.984656587012033,\n",
       "     92.97426268500965,\n",
       "     21.666101],\n",
       "    [92.75855246040959,\n",
       "     19.982078842323997,\n",
       "     92.89682495377032,\n",
       "     20.514473160464657],\n",
       "    [91.831615, 21.518411, 91.957078, 21.666101]]},\n",
       "  'temporal': {'interval': [['2023-01-03T04:30:17Z',\n",
       "     '2023-03-14T04:30:25Z']]}},\n",
       " 'license': 'proprietary',\n",
       " 'description': 'Maxar OpenData | BayofBengal Cyclone Mocha May 23',\n",
       " 'item_assets': {'visual': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n",
       "   'roles': ['visual'],\n",
       "   'title': 'Visual Image'},\n",
       "  'data-mask': {'type': 'application/geopackage+sqlite3',\n",
       "   'roles': ['data-mask'],\n",
       "   'title': 'Data Mask'},\n",
       "  'ms_analytic': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n",
       "   'roles': ['data'],\n",
       "   'title': 'Multispectral Image'},\n",
       "  'pan_analytic': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized',\n",
       "   'roles': ['data'],\n",
       "   'title': 'Panchromatic Image'}},\n",
       " 'stac_version': '1.0.0',\n",
       " 'stac_extensions': ['https://stac-extensions.github.io/item-assets/v1.0.0/schema.json']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections = httpx.get(\"https://stac.eoapi.dev/collections\").json()\n",
    "collections[\"collections\"][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are many more collections available through the STAC endpoint. We can list the available collections by their `id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAXAR_BayofBengal_Cyclone_Mocha_May_23',\n",
       " 'MAXAR_Emilia_Romagna_Italy_flooding_may23',\n",
       " 'MAXAR_Gambia_flooding_8_11_2022',\n",
       " 'MAXAR_Marshall_Fire_21_Update',\n",
       " 'MAXAR_Hurricane_Fiona_9_19_2022',\n",
       " 'MAXAR_Hurricane_Ian_9_26_2022',\n",
       " 'MAXAR_Indonesia_Earthquake22',\n",
       " 'MAXAR_Kahramanmaras_turkey_earthquake_23',\n",
       " 'MAXAR_Kalehe_DRC_Flooding_5_8_23',\n",
       " 'MAXAR_volcano_indonesia21',\n",
       " 'MAXAR_New_Zealand_Flooding22',\n",
       " 'MAXAR_New_Zealand_Flooding23',\n",
       " 'MAXAR_Sudan_flooding_8_22_2022',\n",
       " 'MAXAR_afghanistan_earthquake22',\n",
       " 'MAXAR_cyclone_emnati22',\n",
       " 'MAXAR_ghana_explosion22',\n",
       " 'MAXAR_kentucky_flooding_7_29_2022',\n",
       " 'MAXAR_pakistan_flooding22',\n",
       " 'MAXAR_southafrica_flooding22',\n",
       " 'MAXAR_tonga_volcano21',\n",
       " 'MAXAR_yellowstone_flooding22',\n",
       " 'MAXAR_Maui_Hawaii_fires_Aug_23',\n",
       " 'MAXAR_NWT_Canada_Aug_23',\n",
       " 'MAXAR_shovi_georgia_landslide_8Aug23',\n",
       " 'MAXAR_Hurricane_Idalia_Florida_Aug23',\n",
       " 'MAXAR_Libya_Floods_Sept_2023',\n",
       " 'MAXAR_McDougallCreekWildfire_BC_Canada_Aug_23',\n",
       " 'MAXAR_Morocco_Earthquake_Sept_2023']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c['id'] for c in collections[\"collections\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following steps, we will be using the Kahramanmaras Earthquake collection. A key feature of STAC, is spatial and temporal extents. It is slightly intricate, but a collection can have multiple spatial and temporal extents. \n",
    "\n",
    "**TODO: is multiple extents because of different acquisition dates?**\n",
    "\n",
    "First, let's illustrate the structure for spatial extents, and display them on a map:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spatial extents: 72\n",
      "First spatial extent bounding box: \n",
      " [35.32861203895262, 36.06630343440598, 38.45685512435119, 37.90150133428409]\n"
     ]
    }
   ],
   "source": [
    "collection_id = \"MAXAR_Kahramanmaras_turkey_earthquake_23\"\n",
    "\n",
    "collection_info = httpx.get(f\"https://stac.eoapi.dev/collections/{collection_id}\").json()\n",
    "bboxes = collection_info[\"extent\"][\"spatial\"][\"bbox\"]\n",
    "print(f\"Number of spatial extents: {len(bboxes)}\")\n",
    "print(f\"First spatial extent bounding box: \\n {bboxes[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ac24edcb49490c97a5b4eb1a7c6d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[36.983902384345036, 36.89273358165191], controls=(ZoomControl(options=['position', 'zoom_in_text',…"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": [\n",
    "        {\n",
    "            'type': 'Feature',\n",
    "            'geometry': {\n",
    "                'type': 'Polygon',\n",
    "                'coordinates': [[\n",
    "                    [bbox[0], bbox[1]],\n",
    "                    [bbox[2], bbox[1]],\n",
    "                    [bbox[2], bbox[3]],\n",
    "                    [bbox[0], bbox[3]],\n",
    "                    [bbox[0], bbox[1]],\n",
    "                ]]\n",
    "            },\n",
    "            'properties': {}\n",
    "        }\n",
    "        for bbox in bboxes\n",
    "    ]\n",
    "}\n",
    "\n",
    "mainbbox = collection_info[\"extent\"][\"spatial\"][\"bbox\"][0]\n",
    "\n",
    "m = ipyleaflet.leaflet.Map(\n",
    "    center=((mainbbox[1] + mainbbox[3]) / 2,(mainbbox[0] + mainbbox[2]) / 2),\n",
    "    zoom=7\n",
    ")\n",
    "\n",
    "geo_json = ipyleaflet.leaflet.GeoJSON(data=geojson)\n",
    "m.add_layer(geo_json)\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for temporal extents, you can also have multiple extents. However, the convention is for the first temporal extent to encapsulate the entire range of dates of the sub-extents. In the case of Maxar's collections, there is a single temporal extent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of temporal extents: 1\n",
      "Temporal extent: \n",
      " ['2021-02-28T08:10:22Z', '2023-03-11T08:29:15Z']\n"
     ]
    }
   ],
   "source": [
    "temporal_extents = collection_info[\"extent\"][\"temporal\"]['interval']\n",
    "print(f\"Number of temporal extents: {len(temporal_extents)}\")\n",
    "print(f\"Temporal extent: \\n {temporal_extents[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
