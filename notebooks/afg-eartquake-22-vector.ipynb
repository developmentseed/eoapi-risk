{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake Impact Analysis in Afghanistan (2022)\n",
    "\n",
    "## Objective\n",
    "This notebook aims to analyze and visualize the impact of earthquakes in Afghanistan during the year 2022. By integrating and examining various geospatial datasets, we seek to identify the populations most affected by these seismic events.\n",
    "\n",
    "## Steps of the Analysis\n",
    "\n",
    "1. **Data Retrieval:**\n",
    "   - Fetching vector data from the eoAPI.\n",
    "   - Listing available datasets related to earthquakes and population density in Afghanistan.\n",
    "\n",
    "2. **Data Visualization:**\n",
    "   - Adding hexbin and shakemap layers to an interactive map.\n",
    "   - Styling the layers for better understanding and differentiation.\n",
    "\n",
    "3. **Data Processing:**\n",
    "   - Performing a spatial join using the centroids of hexagons to avoid duplicates.\n",
    "   - Ensuring the accuracy and relevance of the merged data.\n",
    "\n",
    "4. **In-depth Analysis:**\n",
    "   - Visualizing the `paramvalue` attribute of the joined layer to assess earthquake intensity.\n",
    "   - Analyzing the relationship between population density and earthquake intensity.\n",
    "   \n",
    "5. **Conclusion and Implications:**\n",
    "   - Summarizing key findings and insights.\n",
    "   - Discussing the implications for earthquake preparedness and response in Afghanistan.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup\n",
    "\n",
    "Before diving into the analysis, it's important to set up our environment by importing all the necessary libraries. This includes libraries for handling HTTP requests, data manipulation, and geospatial analysis. Ensuring that all dependencies are correctly imported at the start helps in avoiding any interruptions in the workflow during the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "!python -m pip install httpx ipyleaflet matplotlib geopandas\n",
    "IPython.display.clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import geopandas as gpd  \n",
    "import pandas as pd\n",
    "import httpx\n",
    "import ipyleaflet \n",
    "\n",
    "# Additional libraries can be added as required for specific tasks\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Retrieval\n",
    "\n",
    "In this initial step, our focus is on fetching the relevant vector data from eoAPI. This involves accessing the ingested datasets that pertain to earthquakes and population density in Afghanistan.\n",
    "\n",
    "We will be using eoAPI's vector endpoints to retrieve information on the vector datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_endpoint = \"https://eoapi.ifrc-risk.k8s.labs.ds.io/vector\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the available datasets by querying the available collections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public.my_data\n",
      "public.population_hexbins_afghanistan\n",
      "public.admin_boundaries_usa_adm0\n",
      "public.admin_boundaries_usa_adm2\n",
      "public.admin_boundaries_usa_adm1\n",
      "public.health_facilities_afg_osm\n",
      "public.earthquake_usgs_gov_shakemap_afg_pga\n",
      "public.earthquake_usgs_gov_shakemap_afg_psa1p0\n",
      "public.earthquake_usgs_gov_shakemap_afg_pgv\n",
      "public.earthquake_usgs_gov_shakemap_afg_psa3p0\n",
      "public.earthquake_usgs_gov_shakemap_afg_psa0p3\n",
      "public.earthquake_usgs_gov_shakemap_afg_mi\n",
      "public.st_subdivide\n",
      "public.st_hexagongrid\n",
      "public.st_squaregrid\n"
     ]
    }
   ],
   "source": [
    "response = httpx.get(f\"{vector_endpoint}/collections\").json()\n",
    "collections = response[\"collections\"]\n",
    "for collection in collections:\n",
    "    print(collection[\"id\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve our goal of identifying the populations most affected by the earthquakes in Afghanistan, we will utilize two key datasets from the eoAPI:\n",
    "\n",
    "1. **Population Hexbins (`public.population_hexbins_afghanistan`):**\n",
    "   This dataset provides detailed information about population density in Afghanistan. The data is structured in hexagonal bins, each representing a specific geographic area, allowing for a precise and comprehensive understanding of population distribution across the country.\n",
    "\n",
    "2. **Earthquake Shakemap (`public.earthquake_usgs_gov_shakemap_afg_pga`):**\n",
    "   The Earthquake Shakemap dataset offers crucial data on the intensity of earthquakes in Afghanistan. This information is vital for assessing the severity of the seismic events and their potential impact on different regions.\n",
    "\n",
    "By integrating these datasets, we aim to create a comprehensive analysis that combines the spatial distribution of the population with the intensity of the earthquake events. This approach will enable us to effectively identify and visualize the areas and populations most affected by the earthquakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_data_url = f\"{vector_endpoint}/collections/public.population_hexbins_afghanistan/items\"\n",
    "population_hexbins_url = f\"{vector_endpoint}/collections/public.earthquake_usgs_gov_shakemap_afg_pga/items\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_items(url, limit=500):\n",
    "    all_items = []\n",
    "    \n",
    "    while True:\n",
    "        response = httpx.get(url, params={\"limit\": limit}, follow_redirects=True)\n",
    "        if response.status_code == 200:\n",
    "            items = response.json()\n",
    "            all_items.extend(items.get(\"features\", []))\n",
    "            next_link = next((link[\"href\"] for link in items.get(\"links\", []) if link.get(\"rel\") == \"next\"), None)\n",
    "            if next_link:\n",
    "                url = next_link\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    return all_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_items = get_all_items(shake_data_url) # takes a few minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexbin_items = get_all_items(population_hexbins_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
